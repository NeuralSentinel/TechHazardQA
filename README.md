# TechHazardQA

We are updating our repository.
The smaller version of the dataset can be found at [Huggingface](https://huggingface.co/datasets/SoftMINER-Group/TechHazardQA).

If you are using this dataset, please cite our paper

```
@misc{banerjee2024unethical,
      title={How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries}, 
      author={Somnath Banerjee and Sayan Layek and Rima Hazra and Animesh Mukherjee},
      year={2024},
      eprint={2402.15302},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

